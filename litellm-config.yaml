# LiteLLM Configuration for Healthcare AI Platform

# Model definitions
model_list:
  - model_name: ollama-qwen
    litellm_params:
      model: ollama/qwen2.5:3b
      api_base: http://ollama:11434

# Guardrails configuration (AIM cloud integration)
guardrails:
  - guardrail_name: aim
    litellm_params:
      guardrail: aim
      mode: [pre_call, post_call]
      api_key: aim-partner_guidepoint-47ced554202db9e09b85184a221044986a3a6a4d4f22e12c
      default_on: true

# LiteLLM settings
litellm_settings:
  # Request timeout (30 seconds)
  request_timeout: 30

  # Logging verbosity
  set_verbose: false

  # Drop params that model doesn't support
  drop_params: true

# Database configuration for storing keys and usage
database_url: postgresql://healthcare:healthcare123@postgres:5432/litellm

# Master key for admin operations (from environment variable)
master_key: ${LITELLM_MASTER_KEY}

# General settings
general_settings:
  # Store model definitions in database
  store_model_in_db: true

  # Enable user authentication
  allow_user_auth: true

  # Default budget and rate limiting
  max_budget: 100
  budget_duration: "30d"

  # Enable key generation
  disable_spend_logs: false
